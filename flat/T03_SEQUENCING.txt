# === FLAT FILE: T03_SEQUENCING.txt ===
# Version: 2025.04.20
# Created by: Mark + ChatGPT
# Included Modules in (THIS) T02_INITIAL_PROCESSING:
#   - FILE: core/gui/prompt_simulator_window.py
#   - FILE: core/control/simulated_dispatcher.py

### Structure Changelog

| Date           |                                  Change Summary                                        |
|----------------|----------------------------------------------------------------------------------------|
| **2025-04-20** | Structure Changelog resumes HERE in T03_SEQUENCING.txt".                               |
| **2025-04-20** | Sequencer utility GUI launched from menu item "Launch Prompt Cycle Test".                               |
|----------------|----------------------------------------------------------------------------------------|

---



# === FILE NAME: core/gui/prompt_simulator_window.py ===

"""
Aurora – Reflexive AI Control Framework
---------------------------------------

Module: core/gui/prompt_simulator_window.py
Authors: ChatGPT and Mark
Created: 2025-04-20
Location: Evans, Colorado
Project: Aurora

This module implements the Prompt Cycle Simulation Utility. It replaces live browser
interaction with a GUI mock environment for testing step-based prompt sequences without
launching ChatGPT or consuming tokens. Prompts intended for the browser are intercepted,
and a manual response may be entered to simulate GPT output.

License:
    This file is part of the Aurora project and is distributed under the terms of
    the MIT License. See the LICENSE file in the project root for details.

WARNING:
    This file may be auto-modified by development tools or AI agents as part of
    the Aurora project workflow. Manual changes should be made cautiously.
    (Meddle if you dare, foolish mortal!)

FLAT Compliance:
    - Registered in: T02_INITIAL_PROCESSING.txt
    - This file participates in the T02-B04_SEQ_CONT branch of development.
    - All session behaviors are tracked and logged through flat file modules.

---

Prompt Simulation Utility

Displays prompts that would be issued by the reflex dispatcher,
allows user to supply simulated responses, and provides UI feedback
for step flow and interaction without launching a browser.
"""

from PySide6.QtWidgets import (
    QDialog, QVBoxLayout, QHBoxLayout,
    QLabel, QListWidget, QTextEdit, QLineEdit, QPushButton
)

from PySide6.QtCore import QThread, QObject, Signal, Slot, Qt, QMetaObject

from core.control import simulated_dispatcher

class PromptSimulatorWindow(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Aurora – Prompt Cycle Simulator")
        self.setMinimumSize(700, 500)

        self.layout = QVBoxLayout(self)

        # --- Prompt Preview ---
        self.prompt_label = QLabel("Injected Prompt (Simulated):")
        self.prompt_display = QTextEdit()
        self.prompt_display.setReadOnly(True)

        # --- Begin Sequence Button ---
        self.run_button = QPushButton("Run Sequence")
        self.run_button.clicked.connect(self.begin_sequence)
        self.layout.addWidget(self.run_button)

        # --- Simulated GPT Response ---
        self.reply_label = QLabel("Enter Simulated GPT Response:")
        self.reply_input = QLineEdit()
        self.send_button = QPushButton("Send Response")
        self.send_button.clicked.connect(self.send_response)

        # --- Step History and Response Log ---
        self.step_log = QListWidget()
        self.step_log.setFixedHeight(120)
        self.step_log_label = QLabel("Sequence Step Log:")

        self.reply_log = QListWidget()
        self.reply_log.setFixedHeight(120)
        self.reply_log_label = QLabel("Simulated Response Log:")

        self.status_label = QLabel("Status: Idle")
        self.layout.addWidget(self.status_label)

        # --- Layout Assembly ---
        self.layout.addWidget(self.prompt_label)
        self.layout.addWidget(self.prompt_display)
        self.layout.addWidget(self.reply_label)

        hbox = QHBoxLayout()
        hbox.addWidget(self.reply_input)
        hbox.addWidget(self.send_button)
        self.layout.addLayout(hbox)

        self.layout.addWidget(self.step_log_label)
        self.layout.addWidget(self.step_log)

        self.layout.addWidget(self.reply_log_label)
        self.layout.addWidget(self.reply_log)

        from core.control.simulated_dispatcher import inject_simulator
        inject_simulator(self)

    @Slot(str)
    def inject_prompt(self, prompt_text: str):
        self.prompt_display.setPlainText(prompt_text)
        self.step_log.addItem(f"[Injected] {prompt_text[:80]}")

    def send_response(self):
        response = self.reply_input.text().strip()
        if response:
            self.reply_log.addItem(f"[User] {response}")
            self.reply_input.clear()
            self.prompt_display.clear()
            simulated_dispatcher.response_queue.put(response)

    def begin_sequence(self):
        self.status_label.setText("Status: Running...")
        try:
            seq_id = self.parent().ui.pb_sequence_arm.property("sequence_id")
        except AttributeError:
            print("[PromptSimulatorWindow] Could not access sequence ID.")
            return

        if seq_id is None:
            print("[PromptSimulatorWindow] No sequence ID armed.")
            return

        self.thread = QThread()
        self.runner = SequenceRunner(seq_id)
        self.runner.moveToThread(self.thread)
        self.thread.started.connect(self.runner.run)
        self.runner.finished.connect(self.thread.quit)
        self.runner.finished.connect(self.runner.deleteLater)
        self.thread.finished.connect(self.thread.deleteLater)

        print(f"[PromptSimulatorWindow] Running sequence {seq_id} in background thread.")
        self.thread.start()

    @Slot()
    def on_sequence_complete(self):
        self.status_label.setText("Status: Sequence complete.")

class SequenceRunner(QObject):
    finished = Signal()

    def __init__(self, sequence_id):
        super().__init__()
        self.sequence_id = sequence_id

    @Slot()
    def run(self):
        import threading
        print(f"[DEBUG] Running in thread: {threading.current_thread().name}")
        from core.control.sequence_controller import SequenceController
        controller = SequenceController(sequence_id=self.sequence_id, simulated=True)
        controller.run()
        QMetaObject.invokeMethod(
            self.parent(),  # assumes parent is PromptSimulatorWindow
            "on_sequence_complete",
            Qt.QueuedConnection
        )
        self.finished.emit()

if __name__ == "__main__":
    from PySide6.QtWidgets import QApplication
    import sys
    app = QApplication(sys.argv)
    window = PromptSimulatorWindow()
    window.show()
    simulated_dispatcher.inject_simulator(window)
    sys.exit(app.exec())



# === FILE NAME: core/control/simulated_dispatcher.py ===

"""
Aurora – Reflexive AI Control Framework
---------------------------------------

Module: core/control/simulated_dispatcher.py
Authors: ChatGPT and Mark
Created: 2025-04-20
Location: Evans, Colorado
Project: Aurora

Simulated dispatcher module that replaces browser interaction with GUI-driven
manual prompt/response exchange. Used for development, testing, and verification
of sequence behavior without launching an actual ChatGPT session.

License:
    This file is part of the Aurora project and is distributed under the terms of
    the MIT License. See the LICENSE file in the project root for details.

WARNING:
    This file may be auto-modified by development tools or AI agents as part of
    the Aurora project workflow. Manual changes should be made cautiously.
    (Meddle if you dare, foolish mortal!)

FLAT Compliance:
    - Registered in: T03_SEQUENCING.txt
    - This file participates in the T02-B04_SEQ_CONT branch of development.
    - Used in place of reflex_dispatcher during simulation mode.
---

Simulated Reflex Dispatcher

Provides prompt injection and wait emulation without launching a browser.
Prompts appear in the PromptSimulatorWindow; replies are entered manually.
"""

import time
import os
import sys
from queue import Queue

# Ensure 'data' is in sys.path for correct resolution of db_interface
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))
from data.db_interface import resolve_reflex_action

# This global is populated externally
simulator_instance = None
response_queue = Queue()

def inject_simulator(sim):
    global simulator_instance
    simulator_instance = sim
    print("[SimulatedDispatcher] Simulator connected.")

def dispatch_step(step: dict) -> str:
    """
    Handle a single sequence step in simulation mode.
    Instead of browser actions, prompt and response are handled via UI.
    """
    if simulator_instance is None:
        print("[SimulatedDispatcher] ERROR: No simulator attached.")
        return "(Simulator not ready)"

    command = step.get("command", "").strip()

    # If no command, attempt reflex resolution
    if not command:
        reflex_id = step.get("reflex_action", 0)
        if reflex_id:
            try:
                command = resolve_reflex_action(reflex_id)
                if command:
                    print(f"[SimulatedDispatcher] Resolved reflex_action {reflex_id} to command: {command}")
                else:
                    print(f"[SimulatedDispatcher] ERROR: reflex_action {reflex_id} returned nothing.")
            except Exception as e:
                print(f"[SimulatedDispatcher] ERROR resolving reflex_action {reflex_id}: {e}")

            # === INSERT TRANSLATION LOGIC HERE ===
            if command and command.upper() == "LAUNCH BROWSER":
                command = "PROMPT: [Simulated browser launch triggered.]"

    # Still nothing? Bail.
    if not command:
        print("[SimulatedDispatcher] ERROR: Step has no command after reflex resolution. Skipping.")
        return "(No command found in step)"

    if command.startswith("PROMPT:"):
        prompt_text = command[len("PROMPT:"):].strip()
        from PySide6.QtCore import QMetaObject, Qt, Q_ARG

        QMetaObject.invokeMethod(
            simulator_instance,
            "inject_prompt",
            Qt.QueuedConnection,
            Q_ARG(str, prompt_text)
        )

        print(f"[SimulatedDispatcher] Prompt sent to simulator: {prompt_text[:80]}")

        # Block until simulated response is received
        print("[SimulatedDispatcher] Waiting for user response...")
        while response_queue.empty():
            time.sleep(0.1)

        reply = response_queue.get()
        print(f"[SimulatedDispatcher] Received simulated reply: {reply}")
        return reply

    elif command.startswith("WAIT:"):
        seconds = int(command[len("WAIT:"):].strip())
        print(f"[SimulatedDispatcher] Simulated wait for {seconds} seconds.")
        time.sleep(seconds)
        return f"(Simulated) Waited {seconds} seconds."

    elif command.upper().startswith("CHECK:"):
        token = command[6:].strip().strip("/")
        print(f"[SimulatedDispatcher] Simulated check for token: /{token}/ (not implemented)")
        return f"(Simulated) CHECK:/{token}/"

    else:
        print(f"[SimulatedDispatcher] Unhandled command: {command}")
        return f"(Simulated) Unhandled: {command}"



[END T03_SEQUENCING.txt]
